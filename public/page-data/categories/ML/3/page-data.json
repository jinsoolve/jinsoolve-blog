{"componentChunkName":"component---src-templates-category-page-tsx","path":"/categories/ML/3/","result":{"data":{"allMdx":{"totalCount":22,"nodes":[{"frontmatter":{"thumbnail":null,"title":"12장 다층 인공 신경망을 밑바닥부터 구현","updatedAt":null,"createdAt":"2025/01/09","description":"딥러닝은 인공 신경망을 효과적으로 학습시키기 위한 머신러닝의 하위분야이다. 아래 내용을 소개하겠다.- 다층 신경망 개념- 역전파 알고리즘- 이미지 분류를 위한 다층 신경망 훈련","slug":"ml-textbook-12","categories":["ML"]},"excerpt":"딥러닝은 인공 신경망을 효과적으로 학습시키기 위한 머신러닝의 하위분야이다. 아래 내용을 소개하겠다. 다층 신경망 개념 역전파 알고리즘 이미지 분류를 위한 다층 신경망 훈련\n\n인…"},{"frontmatter":{"thumbnail":null,"title":"가중치 w와 L2 규제","updatedAt":null,"createdAt":"2025/01/06","description":"왜 norm을 사용하는 것이 과대적합을 해결할까? 그 이유를 살펴보자.","slug":"ml-textbook-2","categories":["ML"]},"excerpt":"모델이 과대적합이 되었을 때 우리는 norm을 통해 이를 해결한다. 그런데 왜 norm을 사용하는 것이 과대적합을 해결할까? 그 이유를 살펴보자.\n\n모델이 과도하게 훈련 데이터에만…"},{"frontmatter":{"thumbnail":null,"title":"머신러닝 분류 모델들","updatedAt":null,"createdAt":"2025/01/06","description":"머신러닝에 사용하는 다양한 분류 모델들에 대해서 얘기해 보겠다.","slug":"ml-textbook-3","categories":["ML"]},"excerpt":"머신러닝에 사용하는 다양한 분류 모델들에 대해서 얘기해 보겠다. SVM(Support Vector Machine)이라 불리는 이 분류 모델은 클래스를 구분하는 hyper…"},{"frontmatter":{"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/c8138af222d0a534b9d3f8006c1ec625/c497a/cover.png","srcSet":"/static/c8138af222d0a534b9d3f8006c1ec625/88418/cover.png 193w,\n/static/c8138af222d0a534b9d3f8006c1ec625/5b669/cover.png 385w,\n/static/c8138af222d0a534b9d3f8006c1ec625/c497a/cover.png 770w","sizes":"(min-width: 770px) 770px, 100vw"},"sources":[{"srcSet":"/static/c8138af222d0a534b9d3f8006c1ec625/e91f5/cover.webp 193w,\n/static/c8138af222d0a534b9d3f8006c1ec625/94672/cover.webp 385w,\n/static/c8138af222d0a534b9d3f8006c1ec625/75d07/cover.webp 770w","type":"image/webp","sizes":"(min-width: 770px) 770px, 100vw"}]},"width":770,"height":709.9999999999999}}},"title":"로지스틱 회귀의 비용 함수는 왜 이렇게 생겼을까?","updatedAt":null,"createdAt":"2024/12/26","description":"로지스틱 회귀의 비용 함수는 왜 이렇게 생겼을까?","slug":"ml-textbook-1","categories":["ML","short"]},"excerpt":"로지스틱 회귀의 비용함수는 다음과 같이 생겼다. J(w)=−1m∑i=1m[y(i)log(σ(z(i)))+(1−y(i))log(1−σ(z(i)))]J(w) = -\\frac{1}{m…"}],"pageInfo":{"currentPage":3,"pageCount":3}},"ogimage":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/f689f8b3b021090c7d4495f61be56e2f/ee21c/og-image.png","srcSet":"/static/f689f8b3b021090c7d4495f61be56e2f/5fe58/og-image.png 256w,\n/static/f689f8b3b021090c7d4495f61be56e2f/5ca6c/og-image.png 512w,\n/static/f689f8b3b021090c7d4495f61be56e2f/ee21c/og-image.png 1024w","sizes":"(min-width: 1024px) 1024px, 100vw"},"sources":[{"srcSet":"/static/f689f8b3b021090c7d4495f61be56e2f/e818d/og-image.webp 256w,\n/static/f689f8b3b021090c7d4495f61be56e2f/7948c/og-image.webp 512w,\n/static/f689f8b3b021090c7d4495f61be56e2f/aa8b2/og-image.webp 1024w","type":"image/webp","sizes":"(min-width: 1024px) 1024px, 100vw"}]},"width":1024,"height":600}},"profileImage":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/9379464f2e13cd33a2639502a84c1285/4f0b5/profile.jpg","srcSet":"/static/9379464f2e13cd33a2639502a84c1285/cb2c7/profile.jpg 103w,\n/static/9379464f2e13cd33a2639502a84c1285/66f23/profile.jpg 207w,\n/static/9379464f2e13cd33a2639502a84c1285/4f0b5/profile.jpg 413w","sizes":"(min-width: 413px) 413px, 100vw"},"sources":[{"srcSet":"/static/9379464f2e13cd33a2639502a84c1285/8e689/profile.webp 103w,\n/static/9379464f2e13cd33a2639502a84c1285/43852/profile.webp 207w,\n/static/9379464f2e13cd33a2639502a84c1285/f76dc/profile.webp 413w","type":"image/webp","sizes":"(min-width: 413px) 413px, 100vw"}]},"width":413,"height":531}}},"pageContext":{"limit":9,"skip":18,"numPages":3,"currentPage":3,"category":"ML"}},"staticQueryHashes":["3461282698","655531792"],"slicesMap":{}}