{"componentChunkName":"component---src-templates-post-page-tsx-content-file-path-users-jinsoo-git-jinsoolve-blog-content-paper-quantized-side-tuning-untitled-md","path":"/posts/Quantized Side Tuning/","result":{"data":{"post":{"frontmatter":{"slug":"Quantized Side Tuning","title":"Quantized Side Tuning 논문 리뷰","locale":null,"description":"Quantized Side Tuning: Fast and Memory-Efficient Tuning ofQuantized Large Language Models 논문에 대한 리뷰를 작성한 글입니다.","categories":["paper"],"tags":null,"createdAt":"2025/03/11","updatedAt":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/f566903779599cee1d9c25328b1d3436/a5e5c/cover.png","srcSet":"/static/f566903779599cee1d9c25328b1d3436/13d64/cover.png 627w,\n/static/f566903779599cee1d9c25328b1d3436/5404f/cover.png 1253w,\n/static/f566903779599cee1d9c25328b1d3436/a5e5c/cover.png 2506w","sizes":"(min-width: 2506px) 2506px, 100vw"},"sources":[{"srcSet":"/static/f566903779599cee1d9c25328b1d3436/9ac18/cover.webp 627w,\n/static/f566903779599cee1d9c25328b1d3436/06a54/cover.webp 1253w,\n/static/f566903779599cee1d9c25328b1d3436/21a7f/cover.webp 2506w","type":"image/webp","sizes":"(min-width: 2506px) 2506px, 100vw"}]},"width":2506,"height":1368}}}},"myTableOfContents":{"items":[{"depth":1,"title":"Abstract","url":"#my-heading-1","items":[]},{"depth":1,"title":"1 Introduction","url":"#my-heading-2","items":[]},{"depth":1,"title":"2 Related Work","url":"#my-heading-3","items":[{"depth":2,"title":"2.1 Parameter-Efficient Finetuning","url":"#my-heading-4","items":[]},{"depth":2,"title":"2.2 Memory-Efficient Training and Finetuning","url":"#my-heading-5","items":[{"depth":3,"title":"가역 신경망","url":"#my-heading-6","items":[]},{"depth":3,"title":"네트워크 압축","url":"#my-heading-7","items":[]},{"depth":3,"title":"QLoRA","url":"#my-heading-8","items":[]},{"depth":3,"title":"Side Network","url":"#my-heading-9","items":[]}]}]},{"depth":1,"title":"3 Quantized Side Tuning","url":"#my-heading-10","items":[{"depth":2,"title":"3.1 4-bit Quantization","url":"#my-heading-11","items":[]},{"depth":2,"title":"3.2 Side Tuning","url":"#my-heading-12","items":[{"depth":3,"title":"훈련 단계에서의 메모리 점유율","url":"#my-heading-13","items":[]},{"depth":3,"title":"QLoRA의 한계","url":"#my-heading-14","items":[]},{"depth":3,"title":"기존 연구의 한계","url":"#my-heading-15","items":[]}]}]}]}},"otherLocalePost":{"nodes":[{"frontmatter":{"locale":null}}]},"relatedPosts":{"nodes":[{"frontmatter":{"slug":"PoisonedRAG","title":"PoisonedRAG 논문 리뷰","description":"PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generationof Large Language Models 에 관한 논문 리뷰","categories":["paper"],"tags":null,"createdAt":"2025/01/14","updatedAt":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6fb75eab4e07db27e99a999159c25605/721a0/cover.png","srcSet":"/static/6fb75eab4e07db27e99a999159c25605/dd776/cover.png 436w,\n/static/6fb75eab4e07db27e99a999159c25605/fb284/cover.png 872w,\n/static/6fb75eab4e07db27e99a999159c25605/721a0/cover.png 1744w","sizes":"(min-width: 1744px) 1744px, 100vw"},"sources":[{"srcSet":"/static/6fb75eab4e07db27e99a999159c25605/04210/cover.webp 436w,\n/static/6fb75eab4e07db27e99a999159c25605/38eb8/cover.webp 872w,\n/static/6fb75eab4e07db27e99a999159c25605/eb588/cover.webp 1744w","type":"image/webp","sizes":"(min-width: 1744px) 1744px, 100vw"}]},"width":1744,"height":846}}}},"excerpt":"위 글은 PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generationof Large Language…"}]}},"pageContext":{"categories":["paper"],"tags":null,"slug":"Quantized Side Tuning","id":"68113aef-b729-5189-9424-0be28677faaa","myTableOfContents":{"items":[{"depth":1,"title":"Abstract","url":"#my-heading-1","items":[]},{"depth":1,"title":"1 Introduction","url":"#my-heading-2","items":[]},{"depth":1,"title":"2 Related Work","url":"#my-heading-3","items":[{"depth":2,"title":"2.1 Parameter-Efficient Finetuning","url":"#my-heading-4","items":[]},{"depth":2,"title":"2.2 Memory-Efficient Training and Finetuning","url":"#my-heading-5","items":[{"depth":3,"title":"가역 신경망","url":"#my-heading-6","items":[]},{"depth":3,"title":"네트워크 압축","url":"#my-heading-7","items":[]},{"depth":3,"title":"QLoRA","url":"#my-heading-8","items":[]},{"depth":3,"title":"Side Network","url":"#my-heading-9","items":[]}]}]},{"depth":1,"title":"3 Quantized Side Tuning","url":"#my-heading-10","items":[{"depth":2,"title":"3.1 4-bit Quantization","url":"#my-heading-11","items":[]},{"depth":2,"title":"3.2 Side Tuning","url":"#my-heading-12","items":[{"depth":3,"title":"훈련 단계에서의 메모리 점유율","url":"#my-heading-13","items":[]},{"depth":3,"title":"QLoRA의 한계","url":"#my-heading-14","items":[]},{"depth":3,"title":"기존 연구의 한계","url":"#my-heading-15","items":[]}]}]}]},"readingTime":{"text":"7 min read","minutes":6.402,"time":384120,"words":3201},"frontmatter":{"slug":"Quantized Side Tuning","title":"Quantized Side Tuning 논문 리뷰","description":"Quantized Side Tuning: Fast and Memory-Efficient Tuning ofQuantized Large Language Models 논문에 대한 리뷰를 작성한 글입니다.","thumbnail":"cover.png","categories":["paper"],"tags":null,"createdAt":"2025/03/11","updatedAt":null,"featured":true,"locale":null}}},"staticQueryHashes":["3461282698"],"slicesMap":{}}